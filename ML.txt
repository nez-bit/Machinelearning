
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import math
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

#importing dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
ds = pd.read_csv(url)
ds.head()
#analyzing data using seaborn
sns.countplot(x= "1",data = ds)
sns.countplot(x= "1",hue = "6", data = ds)
ds['50'].hist(figsize= (9,9))
#choosing train and test data
x = ds.drop(["1"], axis = 1)
y = ds["1"]
#splitting train and test data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)
m = [0,1,2,3,4] 
m[0] = LogisticRegression()
m[1] = KNeighborsClassifier()
m[2] = DecisionTreeClassifier()
m[3] = GaussianNB()
m[4] = SVC()
for i in range(5):
    m[i].fit(x_train, y_train)
    prediction = m[i].predict(x_test)
    print(classification_report(y_test, prediction))
    print(confusion_matrix(y_test, prediction))
    